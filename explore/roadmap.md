---
description: What's coming up next in Obsrv
---

# Roadmap

Following table captures the high level road-map planned for the next few releases of Obsrv.&#x20;

<table><thead><tr><th width="290">Capability</th><th>Description</th></tr></thead><tbody><tr><td>Connectors Management APIs</td><td>Ability to add and manage a connector into Obsrv via APIs</td></tr><tr><td>Job Framework</td><td>Ability to create and drop in a stream (Flik) or batch job (Spark) into Obsrv</td></tr><tr><td>Job Management APIs</td><td>Ability to add and manage custom jobs in Obsrv via APIs</td></tr><tr><td>Obsrv Exporter</td><td>Export open telemetry compliant monitoring data out to be able to integrate with any external monitoring system</td></tr><tr><td>Support additional data formats</td><td>Add capability to support Parquet, Avro, ORC and XML data formats out of the box</td></tr><tr><td>Auto-Schema Detection</td><td>Add capability to auto-detect the schema (both input data and storage table) based on the data format and connector type</td></tr><tr><td>Schema Evolution</td><td>Add capability to ensure that schema evolution is handled automatically at the processing and storage layer</td></tr><tr><td>Masking &#x26; Encryption</td><td>Add capability to mask or encrypt the data while flowing in to address data privacy concerns</td></tr><tr><td>JSONata and SQL Transformations</td><td>Add capability to provide custom transformation scripts in JSONata or SQL which perform transformations in real-time</td></tr><tr><td>LakeHouse</td><td>Add capability for lakehouse. Hudi is already tested and is in experimental mode. It is now being battle hardened before being added as part of open-source</td></tr><tr><td>Right to be forgotten</td><td>Add scripts to provide the ability to safely delete a dataset from all storages</td></tr><tr><td>Data Aliases</td><td>Add aliases to tables or datasources (similar to ElasticSearch) so that data replay and migrations are simplified and can be performed without any downtime</td></tr><tr><td>Query Access Control</td><td>Add capability to add access control of the data via OPA rules. An API to manage all access policies across any dataset</td></tr><tr><td>Sink Connectors</td><td>Add capability to reverse ETL the processed and enriched data</td></tr><tr><td>Auto Scaling</td><td>Add ability to auto-scale the infra based on processing speed, data lag/back-pressure and query response times</td></tr><tr><td>API Management</td><td>Add ability to configure consume tokens for the APIs so that integrations with end-user systems are seamless</td></tr><tr><td>New Connectors</td><td><p>Add new Database connectors - Oracle, SQL Server, MongoDB, Cassandra, ElasticSearch</p><p>Add new Stream connectors - Postgresql Debezium, MySQL Debezium, DB2 Debezium, Oracle Debezium, SQL Server Debezium, MongoDB Debezium, Cassandra Debezium</p><p>Add new File connectors - Azure Blob Storage, MinIO, Google Cloud Storage</p></td></tr><tr><td>Simplified Archival and Retention policies</td><td>Ability to apply the archival and retention policy on the datasets and table via a unified API without any knowledge about the underlying storage (whether the data is stored in Hudi or Druid)</td></tr></tbody></table>

